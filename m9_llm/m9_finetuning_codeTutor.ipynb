{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhrg_-aWG-Ds","executionInfo":{"status":"ok","timestamp":1723625496920,"user_tz":-540,"elapsed":43796,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"3cf1f0c1-03df-4667-e768-4135f04e5e82"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install -q tiktoken\n","%pip install -q cohere\n","%pip install -q openai\n","%pip install -q gradio"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from openai import OpenAI\n","import gradio as gr\n","import time\n","import json\n","\n","\n","## Set the API key and model name\n","MODEL=\"gpt-4o-mini-2024-07-18\"\n","client = OpenAI(api_key=\"sk-proj-upOVy97VapEQl5kOiTQIT3BlbkFJlKBrtAnjDU5YMvWrqMzd\")"],"metadata":{"id":"HMipRPoAIijj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 만들기\n","import pandas as pd\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","df = pd.read_excel('/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft.xlsx', engine='openpyxl')\n","df.head()"],"metadata":{"id":"CKkdGU-KGY7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습용 평가용 데이터 분리\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","file_path = '/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft.xlsx'  # Replace with your file path\n","data = pd.read_excel(file_path)\n","train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"],"metadata":{"id":"_mraV9DhGaHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# 파일 경로\n","file_path = '/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft.xlsx'  # 실제 경로로 변경하세요\n","data = pd.read_excel(file_path)\n","\n","# Train-test split\n","train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# System message\n","system_msg = \"\"\"코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇입니다. 학생이 선택한 섹션에 대해 충분한 학습을 할 수 있도록 각 섹션별 학습 항목에 대해서 하나씩 개념을 명확하게 설명하고 연습문제를 2, 3개를 제공해서 각 개념을 응용해서 이해할 수 있는 기회를 제공합니다.\n","\n","    **각 섹션별 학습내용과 목표는 다음과 같습니다:**\n","\n","    1. 파이썬 기초\n","      변수와 자료형 이해: 파이썬에서 변수와 다양한 자료형(정수, 실수, 문자열 등)을 이해하고 사용할 수 있다.\n","      기본 연산 수행: 기본 산술 연산(덧셈, 뺄셈, 곱셈, 나눗셈)과 논리 연산을 이해하고 활용할 수 있다.\n","      입출력 처리: 표준 입력과 출력 함수를 사용하여 사용자로부터 데이터를 입력받고, 결과를 출력할 수 있다.\n","      조건문 이해와 활용: if, elif, else 조건문을 사용하여 프로그램의 흐름을 제어할 수 있다.\n","      반복문 이해와 활용: for, while 반복문을 사용하여 반복적인 작업을 수행할 수 있다.\n","      기본 프로그램 작성: 위 개념들을 종합적으로 활용하여 간단한 파이썬 프로그램을 작성할 수 있다.\n","    2. 파이썬 응용\n","      리스트 활용: 리스트 자료형을 이해하고, 리스트의 생성, 수정, 삭제, 접근 등의 작업을 수행할 수 있다.\n","      조건문과 반복문 응용: 조건문과 반복문을 복합적으로 사용하여 다양한 문제를 해결할 수 있다.\n","      문자열 처리: 문자열 자료형의 다양한 메서드를 사용하여 문자열을 처리하고 조작할 수 있다.\n","      함수 작성 및 활용: 파이썬 함수의 개념을 이해하고, 매개변수와 반환값을 사용하여 재사용 가능한 코드를 작성할 수 있다.\n","      딕셔너리 활용: 딕셔너리 자료형을 이해하고, 키-값 쌍을 사용하여 데이터를 저장하고 조작할 수 있다.\n","      문제 정의와 해결: 리스트, 조건문, 반복문, 문자열 처리, 함수, 딕셔너리를 활용하여 실제 문제를 정의하고 해결할 수 있는 프로그램을 작성할 수 있다.\n","\n","\n","    **튜터링 프로세스**:\n","\n","    1. 학생들을 환영합니다.\n","    2. 학생들이 학습할 섹션을 선택하게 합니다.\n","    3. 각 섹션에 포함되는 학습할 내용들에 대해서 하나씩 개념을 이해하고 문제를 풀 수 있도록 합니다. 문제는 최소한 2개 이상 제시합니다.\n","\n","    4. 각 문제에 대한 학생의 답안을 신중하게 확인하고 학생들의 이해도를 향상시킬 수 있도록 적합한 설명을 추가합니다.\n","    5. 학습자의 이해 정도에 따라서 문제를 단계 별로 해결할 수 있도록 설명한다.\n","    6. 초보자가 입력한 코드에 오류가 있는지 주의 깊게 확인하고 오류를 해결할 수 있는 피드백을 제공합니다.\n","    7. 학습자의 이해 정도를 파악해서 추가적인 학습을 할 지 여부를 판단한 후 다음 주제로 넘어갈 지를 결정합니다.\n","\n","    8. 다음 세션으로 넘어가기 전에 학습자가 각 세션에 대한 내용을 충분히 이해했는 지 확인한 후 진행합니다.\n","    9. 대화는 간결하게 유지하며, 최대 30자 이내로 답변합니다.\n","\n","    **학생과의 상호작용**:\n","   튜터봇은 학생들이 자기주도 학습을 할 수 있도록 개인화 된 학습을 제공하고 모든 질의 응답을 한국어로 진행합니다.\n","\"\"\"\n","\n","# Function to convert DataFrame to formatted JSON\n","def convert_to_json(df):\n","    formatted_data = []\n","    temp_message = [{\"role\": \"system\", \"content\": system_msg}]\n","    for i, row in df.iterrows():\n","        # Check if content exists and is a valid string\n","        if pd.notna(row['content']) and isinstance(row['content'], str):\n","            message = {\"role\": row['role'], \"content\": row['content']}\n","            if row['role'] == 'assistant' and pd.notna(row.get('weight')):\n","                message[\"weight\"] = int(row['weight'])\n","            temp_message.append(message)\n","            if row['role'] == 'assistant':\n","                formatted_data.append({\"messages\": temp_message})\n","                temp_message = [{\"role\": \"system\", \"content\": system_msg}]\n","        else:\n","            print(f\"Skipping row {i} due to missing or invalid content.\")\n","    return formatted_data\n","\n","# Convert the DataFrame to JSON format\n","train_dataset_formatted = convert_to_json(train_data)\n","val_dataset_formatted = convert_to_json(val_data)\n","\n","# Print formatted JSON\n","import json\n","formatted_json = json.dumps(train_dataset_formatted, indent=2, ensure_ascii=False)\n","print(formatted_json)\n"],"metadata":{"id":"umYOQShVGeF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","ds_sample = train_dataset_formatted\n","with open('/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_train.jsonl', 'w') as f:\n","  for line in ds_sample:\n","    json.dump(line, f)\n","    f.write('\\n')"],"metadata":{"id":"IFmI-SWzGinf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","ds_sample = val_dataset_formatted\n","with open('/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_valid.jsonl', 'w') as f:\n","  for line in ds_sample:\n","    json.dump(line, f)\n","    f.write('\\n')"],"metadata":{"id":"1jf4QNnLGmEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import tiktoken\n","import numpy as np\n","from collections import defaultdict\n","\n","data_path = '/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_train.jsonl'\n","# Load the dataset\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    train_dataset = [json.loads(line) for line in f]\n","\n","# Initial dataset stats\n","print(\"First 3 examples:\")\n","for i in range(3):\n","    print(f\"Example {i+1}:\")\n","    for message in train_dataset[i][\"messages\"]:\n","        print(message)\n","    print(\"\\n\")  # Add a newline for better readability between examples"],"metadata":{"id":"i40UutzRGoau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import tiktoken\n","import numpy as np\n","from collections import defaultdict\n","\n","data_path = '/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_valid.jsonl'\n","# Load the dataset\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    val_dataset = [json.loads(line) for line in f]\n","\n","# Initial dataset stats\n","print(\"Num examples:\", len(val_dataset))\n","print(\"First example:\")\n","for message in val_dataset[0][\"messages\"]:\n","    print(message)"],"metadata":{"id":"UGHh2RtfGtAh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 오류 확인"],"metadata":{"id":"ywVt4jEeGxeD"}},{"cell_type":"code","source":["# Format error checks\n","format_errors = defaultdict(int)\n","\n","for ex in train_dataset:\n","    if not isinstance(ex, dict):\n","        format_errors[\"data_type\"] += 1\n","        continue\n","\n","    messages = ex.get(\"messages\", None)\n","    if not messages:\n","        format_errors[\"missing_messages_list\"] += 1\n","        continue\n","\n","    for message in messages:\n","        if \"role\" not in message or \"content\" not in message:\n","            format_errors[\"message_missing_key\"] += 1\n","\n","        if any(k not in (\"role\", \"content\", \"weight\") for k in message):\n","            format_errors[\"message_unrecognized_key\"] += 1\n","\n","        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n","            format_errors[\"unrecognized_role\"] += 1\n","\n","        content = message.get(\"content\", None)\n","        if not content or not isinstance(content, str):\n","            format_errors[\"missing_content\"] += 1\n","\n","    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","        format_errors[\"example_missing_assistant_message\"] += 1\n","\n","if format_errors:\n","    print(\"Found errors:\")\n","    for k, v in format_errors.items():\n","        print(f\"{k}: {v}\")\n","else:\n","    print(\"No errors found\")"],"metadata":{"id":"hWLUUN-xGyh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Format error checks\n","format_errors = defaultdict(int)\n","\n","for ex in val_dataset:\n","    if not isinstance(ex, dict):\n","        format_errors[\"data_type\"] += 1\n","        continue\n","\n","    messages = ex.get(\"messages\", None)\n","    if not messages:\n","        format_errors[\"missing_messages_list\"] += 1\n","        continue\n","\n","    for message in messages:\n","        if \"role\" not in message or \"content\" not in message:\n","            format_errors[\"message_missing_key\"] += 1\n","\n","        if any(k not in (\"role\", \"content\", \"weight\") for k in message):\n","            format_errors[\"message_unrecognized_key\"] += 1\n","\n","        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n","            format_errors[\"unrecognized_role\"] += 1\n","\n","        content = message.get(\"content\", None)\n","        if not content or not isinstance(content, str):\n","            format_errors[\"missing_content\"] += 1\n","\n","    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","        format_errors[\"example_missing_assistant_message\"] += 1\n","\n","if format_errors:\n","    print(\"Found errors:\")\n","    for k, v in format_errors.items():\n","        print(f\"{k}: {v}\")\n","else:\n","    print(\"No errors found\")"],"metadata":{"id":"KMFon2u3G1S5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["fine tuning"],"metadata":{"id":"5Pvto0WTG6oi"}},{"cell_type":"code","source":["# 데이터 업로드\n","# JSON Lines 파일을 모델 학습에 사용하기 위해 업로드\n","train = client.files.create(\n","  file=open(\"/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_train.jsonl\", \"rb\"),\n","  purpose='fine-tune'\n",")\n","train"],"metadata":{"id":"ppKr1JDhG7nT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid = client.files.create(\n","  file=open(\"/content/drive/MyDrive/kdt_240424/m9_openai/data/code_ft_valid.jsonl\", \"rb\"),\n","  purpose='fine-tune'\n",")\n","valid"],"metadata":{"id":"jUf6xHEjG-TR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["파인튜닝"],"metadata":{"id":"wISe6lNIHDxh"}},{"cell_type":"code","source":["client.fine_tuning.jobs.create(\n","  training_file='file-ymQn1PrbhGl7KLwndLNgFHMh',\n","  validation_file='file-dWhHK73TB1lWH6iLwg1P6vVj',\n","  model=MODEL,\n","  hyperparameters={\n","    \"n_epochs\":3\n","  }\n",")"],"metadata":{"id":"Qhx-drsxHBD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 작업상태 확인\n","response = client.fine_tuning.jobs.retrieve(\"ftjob-bwhRTrexajY7l2yhCdZNzu5H\")\n","\n","# 작업 상태 확인\n","status = response.status\n","\n","if status == \"succeeded\":\n","    print(\"작업이 완료되었습니다.\")\n","    # 작업이 완료되면 결과를 가져와서 사용할 수 있습니다.\n","    # 예를 들어, 모델을 사용하여 텍스트 생성 또는 다른 작업을 수행할 수 있습니다.\n","else:\n","    print(f\"작업 상태: {status}\")\n","\n","total_tokens = response.trained_tokens\n","print(f\"사용된 총 토큰 수: {total_tokens}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luuLNvfvHKEC","executionInfo":{"status":"ok","timestamp":1723559234665,"user_tz":-540,"elapsed":500,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"a825f143-2a5b-4017-b6cf-7bd2cd6b34d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["작업이 완료되었습니다.\n","사용된 총 토큰 수: 31776\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","import gradio as gr\n","import subprocess\n","\n","client = OpenAI(api_key=\"sk-proj-upOVy97VapEQl5kOiTQIT3BlbkFJlKBrtAnjDU5YMvWrqMzd\")\n","\n","def code_print(code, user_input):\n","    modified_code = code.replace('input(\"이름을 입력하세요: \")', f'\"{user_input}\"')\n","    result = subprocess.run([\"python\", \"-c\", modified_code], capture_output=True, text=True)\n","    return result.stdout or result.stderr\n","\n","def answer(state, state_chatbot, text):\n","    if text == \"\":\n","        return state, state_chatbot, state_chatbot\n","\n","    if '```' in text:\n","        code_parts = text.split('```')\n","        code = code_parts[1].strip()\n","        input_value = code_parts[2].strip() if len(code_parts) > 2 else \"\"\n","\n","        output = code_print(code, input_value)\n","\n","        new_state = [{'role': 'user', 'content': text},\n","                     {'role': 'assistant', 'content': output}]\n","        state = state + new_state\n","        state_chatbot = state_chatbot + [(text, output)]\n","        return state, state_chatbot, state_chatbot\n","\n","    messages = state + [{'role': 'user', 'content': text}]\n","\n","    res = client.chat.completions.create(\n","        model=\"ft:gpt-4o-mini-2024-07-18:bnvs::9vhRlPzZ\",\n","        messages=messages\n","    )\n","\n","    msg = res.choices[0].message.content\n","\n","    new_state = [{'role': 'user', 'content': text},\n","                 {'role': 'assistant', 'content': msg}]\n","\n","    state = state + new_state\n","    state_chatbot = state_chatbot + [(text, msg)]\n","\n","    return state, state_chatbot, state_chatbot\n","\n","def start_def(section):\n","    if not section:\n","        return [], [], [(\"섹션을 선택해주세요!\", \"\")]\n","    else:\n","        text = f\"{section} 섹션을 선택하셨습니다. 수업을 시작하겠습니다.\"\n","\n","    system_msg = \"\"\"코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇입니다. 학생이 선택한 섹션에 대해 충분한 교육을 할 수 있도록 학습할 내용을 선별해서 하나씩 전부 개념을 설명하고 연습문제를 2, 3개를 제공해서 연습할 수 있게 합니다.\n","\n","    **각 섹션별 학습내용과 목표는 다음과 같습니다:**\n","\n","    1. 파이썬 기초\n","      변수와 자료형 이해: 파이썬에서 변수와 다양한 자료형(정수, 실수, 문자열 등)을 이해하고 사용할 수 있다.\n","      기본 연산 수행: 기본 산술 연산(덧셈, 뺄셈, 곱셈, 나눗셈)과 논리 연산을 이해하고 활용할 수 있다.\n","      입출력 처리: 표준 입력과 출력 함수를 사용하여 사용자로부터 데이터를 입력받고, 결과를 출력할 수 있다.\n","      조건문 이해와 활용: if, elif, else 조건문을 사용하여 프로그램의 흐름을 제어할 수 있다.\n","      반복문 이해와 활용: for, while 반복문을 사용하여 반복적인 작업을 수행할 수 있다.\n","      기본 프로그램 작성: 위 개념들을 종합적으로 활용하여 간단한 파이썬 프로그램을 작성할 수 있다.\n","    2. 파이썬 응용\n","      리스트 활용: 리스트 자료형을 이해하고, 리스트의 생성, 수정, 삭제, 접근 등의 작업을 수행할 수 있다.\n","      조건문과 반복문 응용: 조건문과 반복문을 복합적으로 사용하여 다양한 문제를 해결할 수 있다.\n","      문자열 처리: 문자열 자료형의 다양한 메서드를 사용하여 문자열을 처리하고 조작할 수 있다.\n","      함수 작성 및 활용: 파이썬 함수의 개념을 이해하고, 매개변수와 반환값을 사용하여 재사용 가능한 코드를 작성할 수 있다.\n","      딕셔너리 활용: 딕셔너리 자료형을 이해하고, 키-값 쌍을 사용하여 데이터를 저장하고 조작할 수 있다.\n","      문제 정의와 해결: 리스트, 조건문, 반복문, 문자열 처리, 함수, 딕셔너리를 활용하여 실제 문제를 정의하고 해결할 수 있는 프로그램을 작성할 수 있다.\n","\n","\n","    **튜터링 프로세스**:\n","\n","    1. 학생들을 환영합니다.\n","    2. 학생들이 학습할 섹션을 선택하게 합니다.\n","    3. 각 섹션에 포함되는 학습할 내용들을 하나씩 개념을 이해하고 문제를 풀 수 있도록 합니다.\n","    4. 학생의 답안을 신중하게 확인하고 올바르게 수정합니다.\n","    5. 학습자의 이해 정도에 따라서 문제를 단계 별로 해결할 수 있도록 설명한다.\n","    6. 초보자가 입력한 코드에 오류가 있는지 주의 깊게 확인하고 적절한 피드백을 제공합니다.\n","    7. 학습자의 이해 정도를 파악해서 추가적인 학습을 할 지 다음 주제로 넘어갈 지를 결정합니다.\n","    8. 대화는 간결하게 유지하며, 최대 30자 이내로 답변합니다.\n","\n","    **학생과의 상호작용**:\n","   튜터봇은 학생들이 자기주도 학습을 할 수 있도록 개인화 된 학습을 제공하고 모든 질의 응답을 한국어로 진행합니다.\n","\"\"\"\n","\n","    message = [{'role': 'system', 'content': system_msg},\n","               {'role': 'user', 'content': text}]\n","\n","    res = client.chat.completions.create(\n","        model=\"ft:gpt-4o-mini-2024-07-18:bnvs::9vhRlPzZ\",\n","        messages=message,\n","        temperature=0.5,\n","    )\n","\n","    msg = res.choices[0].message.content\n","    message.append({'role': 'assistant', 'content': msg})\n","    state_chatbot = [(text, msg)]\n","    return message, state_chatbot, state_chatbot\n","\n","with gr.Blocks(theme='JohnSmith9982/small_and_pretty') as demo:\n","    state = gr.State([])\n","    state_chatbot = gr.State([])\n","\n","    with gr.Row():\n","        gr.HTML(\"\"\"<div style=\"text-align: center; max-width: 550px; margin: 0 auto;\">\n","            <div>\n","              <p style=\"font-size: 40px; font-weight: bold;\">Play CodeSync</p>\n","            </div>\n","            </div>\"\"\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=6):\n","            md = gr.Dropdown([\"파이썬 기초\", \"파이썬 응용\"], type=\"value\", label=\"섹션 선택\", info=\"원하는 섹션을 골라주세요!\")\n","        with gr.Column(scale=4):\n","            gr.HTML(\"\"\"<div style=\"text-align: center;\">\n","                <div>\n","                  <p style=\"font-size: 15px; font-weight: bold;\">학습 시작하기</p>\n","                </div>\n","              </div>\"\"\")\n","            start_btn = gr.Button(\"시작하기\")\n","        with gr.Column(scale=1):\n","            gr.HTML(\"\"\"<div style=\"text-align: center;\">\n","              <div>\n","                <p style=\"font-size: 15px; font-weight: bold;\">다크모드 전환</p>\n","              </div>\n","            </div>\"\"\")\n","            toggle_dark = gr.Button(value=\"Toggle Dark\")\n","            toggle_dark.click(None,\n","                js=\"\"\"() => {\n","                  document.body.classList.toggle('dark');\n","                  document.querySelector('gradio-container').style.backgroundColor = 'var(--color-background-primary)'\n","                  }\n","                \"\"\"\n","            )\n","\n","    with gr.Row():\n","        with gr.Column(scale=1):\n","            chatbot = gr.Chatbot(elem_id='메세지창', height=650)\n","        with gr.Column(scale=1):\n","            with gr.Row():\n","                txt = gr.Textbox(show_label=False, placeholder='메세지를 입력해주세요!')\n","            with gr.Row():\n","                txt_btn = gr.Button(\"메세지 보내기\")\n","            with gr.Row():\n","                txt_input = gr.Textbox(show_label=False, placeholder='코드에서 사용할 입력값을 입력하세요')\n","                code_btn = gr.Button(\"코드 실행\")\n","            with gr.Row():\n","                txt_result = gr.Textbox(label='코드실행결과')\n","\n","    txt_btn.click(answer, [state, state_chatbot, txt], [state, state_chatbot, chatbot])\n","    txt_btn.click(lambda: '', None, txt)\n","    txt.submit(answer, [state, state_chatbot, txt], [state, state_chatbot, chatbot])\n","    txt.submit(lambda: '', None, txt)\n","\n","    def handle_code_execution(txt, txt_input, state, state_chatbot):\n","        state_list = list(state)\n","        state_chatbot_list = list(state_chatbot)\n","        new_state, new_state_chatbot, chatbot_output = answer(state_list, state_chatbot_list, f\"```{txt}```{txt_input}\")\n","        return new_state, new_state_chatbot, chatbot_output, chatbot_output[-1][1]\n","\n","    code_btn.click(handle_code_execution, inputs=[txt, txt_input, state, state_chatbot], outputs=[state, state_chatbot, chatbot, txt_result])\n","    start_btn.click(start_def, inputs=[md], outputs=[state, state_chatbot, chatbot])\n","\n","demo.launch(debug=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":796,"referenced_widgets":["700017a519a94c72ab6884147c347c24","26bc3161c4dc42888322bb66850f49fb","b3c91697c6924aa28202044835c9840a","bda5ca5eb80a4be5b9bcb75b0e0084e1","64540a36d6d1479cbbb9e55445f9102b","60f59f708fc54b359e5251732aeec44f","4f95cbdb44f94903a58e619ea48c97ed","1ca4d86b26d74922a47236b1a8de5217","f74358664afb4d7189e2ba88027683a5","4f675311495e4144b35c60ecf280bfcb","bd51cfda7ced4303b25ba0882349e764"]},"id":"x9ZKKAcJEwO6","outputId":"a9026511-548c-48e8-d1d8-61f6fa9e0b1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["themes/theme_schema@1.0.0.json:   0%|          | 0.00/13.0k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700017a519a94c72ab6884147c347c24"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://61003e129837745064.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://61003e129837745064.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"700017a519a94c72ab6884147c347c24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26bc3161c4dc42888322bb66850f49fb","IPY_MODEL_b3c91697c6924aa28202044835c9840a","IPY_MODEL_bda5ca5eb80a4be5b9bcb75b0e0084e1"],"layout":"IPY_MODEL_64540a36d6d1479cbbb9e55445f9102b"}},"26bc3161c4dc42888322bb66850f49fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60f59f708fc54b359e5251732aeec44f","placeholder":"​","style":"IPY_MODEL_4f95cbdb44f94903a58e619ea48c97ed","value":"themes/theme_schema@1.0.0.json: 100%"}},"b3c91697c6924aa28202044835c9840a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca4d86b26d74922a47236b1a8de5217","max":12968,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f74358664afb4d7189e2ba88027683a5","value":12968}},"bda5ca5eb80a4be5b9bcb75b0e0084e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f675311495e4144b35c60ecf280bfcb","placeholder":"​","style":"IPY_MODEL_bd51cfda7ced4303b25ba0882349e764","value":" 13.0k/13.0k [00:00&lt;00:00, 829kB/s]"}},"64540a36d6d1479cbbb9e55445f9102b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f59f708fc54b359e5251732aeec44f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f95cbdb44f94903a58e619ea48c97ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ca4d86b26d74922a47236b1a8de5217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74358664afb4d7189e2ba88027683a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f675311495e4144b35c60ecf280bfcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd51cfda7ced4303b25ba0882349e764":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}